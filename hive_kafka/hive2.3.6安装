http://m.blog.itpub.net/30089851/viewspace-2082805/
http://www.aboutyun.com/thread-18361-1-1.html

 配置环境变量(如果不是root用户，配置自己的~/.bash_profile即可)：
 vi /etc/profile
 export HIVE_HOME=/home/titanic/soft/hadoop/hive-2.0.0
 export PATH=$HIVE_HOME/bin: $PATH
 source /etc/profile
 -------------------------------------------------------------------------------
 修改hive-env.sh
 export JAVA_HOME=/usr/local/jdk1.7.0_80  
export HADOOP_HOME=/usr/local/hadoop 
 ---------------------------------------------------------------------------------
 安装mysql
 create database hive;
grant all on hive.* to hive@'%' identified by 'a';
grant all on hive.* to hive@localhost identified by 'a';

配置hive-site.xml中jdbc如下
&amp; 相当于 &
jdbc:mysql://127.0.0.1:3306/hive?createDatabaseIfNotExist=true&amp;useSSL=false

mysql驱动Jar放入${HIVE_HOME}/lib目录


hive-site.xml
内容如下
----------------------------------------------------------------------------------------
<?xml version="1.0" encoding="UTF-8" standalone="no"?> 
<?xml-stylesheet type="textl" href="configuration.xsl"?>
<configuration>
<property>
<name>hive.metastore.warehouse.dir</name>
<value>hdfs://127.0.0.1:8020/user/hive/warehouse</value>
<description>Hive在HDFS上的根目录</description>
</property>
<property>
<name>javax.jdo.option.ConnectionURL</name>
<value>jdbc:mysql://127.0.0.1:3306/hive?createDatabaseIfNotExist=true&amp;useSSL=false</value>
<description>Hive元数据库的连接串，红色为数据库名</description>
</property>
<property>
<name>javax.jdo.option.ConnectionDriverName</name>
<value>com.mysql.jdbc.Driver</value>
<description>Hive元数据库JDBC驱动</description>
</property>
<property>
<name>javax.jdo.option.ConnectionUserName</name>
<value>hive</value>
<description>Hive元数据库用户名</description>
</property>
<property>
<name>javax.jdo.option.ConnectionPassword</name>
<value>a</value>
<description>Hive元数据库密码</description>
</property>
<property>
<name>datanucleus.autoCreateTables</name>
<value>true</value>
<description>不存在时，自动创建Hive元数据表</description>
</property>
<property>
<name>datanucleus.autoCreateColumns</name>
<value>true</value>
<description>不存在时，自动创建Hive元数据列</description>
</property>
<property>
<name>datanucleus.fixedDatastore</name>
<value>true</value>
</property>
<property>
<name>datanucleus.autoStartMechanism</name>
<value>SchemaTable</value>
</property>

<!--Hive metastore start -->  
<property>  
  <name>hive.metastore.uris</name>  
  <value>thrift://127.0.0.1:9083</value>  
</property>  

<!--Hive metastore start -->

<property>  
	<name>datanucleus.autoCreateColumns</name>  
	<value>true</value>
</property>
     
</configuration>
------------------------------------------------------------------------------------------------
修改hive日志目录
修改hive/conf/hive-log4j2.properties
property.hive.log.dir =/home/titanic/soft/hadoop/hive-2.0.0/logs
----------------------------------------------------------------------------------------------
初始化hive
.//bin/schematool -dbType mysql -initSchema hive hive
-------------------------------------------------------------------------------------------------
启动顺序不能错，要以一下命令的顺序启动
#启动metastore服务
~ bin/hive --service metastore &
Starting Hive Metastore Server

#启动hiveserver服务
~ bin/hive --service hiveserver2 &
Starting Hive Thrift Server

#启动hive客户端
~ bin/hive shell
Logging initialized using configuration in file:/root/hive-0.9.0/conf/hive-log4j.properties
Hive history file=/tmp/root/hive_job_log_root_201211141845_1864939641.txt

hive> show tables
OK

http://127.0.0.1:10002/hiveserver2.jsp  web页面
-------------------------------------------------------------------
dberver使用jdbc链接hive
修改etc/hadoop/core-site.xml

把root换成系统用户titanic

<property>
    <name>hadoop.proxyuser.titanic.hosts</name>
    <value>*</value>
</property>
<property>
    <name>hadoop.proxyuser.titanic.groups</name>
    <value>*</value>
</property>

dberver中
jdbcurl		jdbc:hive2://binend02:10000/default
主机		binend02      端口10000
数据库		default
用户名		titanic
密码		a


