
1.关闭防火墙
sudo ufw disable

2.修改hostname

3.ssh免密码登录
ssh-keygen -t rsa

每台机器都运行
ssh-copy-id binend@binend01
ssh-copy-id binend@binend02
ssh-copy-id binend@binend03
ssh-copy-id binend@binend04
ssh-copy-id binend@binend05

4.安装jdk

5.下载hadoop3.1.3

6.在hadoop3.1.3/新建3个文件夹
mkdir -pv /home/titanic/soft/hadoop/hadoop-3.1.3/data

7.修改环境变量，添加hadoop环境比那里
sudo vi /etc/profile.d/titanic/sh

#Add HADOOP_HOME PATH
HADOOP_HOME=/home/titanic/soft/hadoop/hadoop-3.1.3/
PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin

sources  /etc/profile.d/titanic/sh

8.修改配置文件
修改 /hadoop-3.1.3/etc/hadoop/hadoop-env.sh 添加

export JAVA_HOME=/usr/lib/jvm/jdk1.8.0_221
----------------------------------------------------------------------
core-site.xml 

<configuration>
    
    参考
    https://github.com/titainic/doc/blob/master/hadoop_config_file/hadoop/core-site.xml
    
</configuration>
----------------------------------------------------------------------
hdfs-site.xml 

<configuration>

        参考
        https://github.com/titainic/doc/blob/master/hadoop_config_file/hadoop/hdfs-site.xml
        
</configuration>
----------------------------------------------------------------------
mapred-site.xml

<configuration>
    
    参考
    https://github.com/titainic/doc/blob/master/hadoop_config_file/hadoop/mapred-site.xml
    
</configuration>
----------------------------------------------------------------------
yarn-site.xml

<configuration>

    参考
    https://github.com/titainic/doc/blob/master/hadoop_config_file/hadoop/yarn-site.xml
    
</configuration>

workers文件中添加子节点
binend02
binend03
binend04
binend05

----------------------------------------------------------------------
9.scp分发到各节点相应目录

10.格式化 hadoop namenode -format

11.修改启动名称避免与spark重合
hadoop3.1.3/sbin/start-all.sh -> hadoop-start-all.sh
hadoop3.1.3/sbin/stop-all.sh -> hadoop-stop-all.sh
